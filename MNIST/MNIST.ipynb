{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "from_numpy = torch.from_numpy\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('cuda is available')\n",
    "else:\n",
    "    print('cuda is not available')\n",
    "store_every = 1000\n",
    "lr0 = 0.02\n",
    "#model_type = 'MLP'\n",
    "model_type = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_transforms = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, \n",
    "        transform=mnist_transforms, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, \n",
    "        transform=mnist_transforms, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        mnist_test, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "class ResLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, activation=nn.ReLU()):\n",
    "        super(ResLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        if in_features != out_features:\n",
    "            self.project_linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inner = self.activation(self.linear(x))\n",
    "        if self.in_features != self.out_features:\n",
    "            skip = self.project_linear(x)\n",
    "        else:\n",
    "            skip = x\n",
    "        return inner + skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 16, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        Flatten(),\n",
    "        ResLinear(256, 100),\n",
    "        nn.ReLU(),\n",
    "        ResLinear(100, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch, total_epochs):\n",
    "    lr = lr0 * (0.1 ** (epoch / float(total_epochs)))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(proba, y):\n",
    "    correct = torch.eq(proba.max(1)[1], y).sum().type(torch.FloatTensor)\n",
    "    return correct / y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset_loader, criterion):\n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    for batch in dataset_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = batch\n",
    "        if model_type == 'MLP':\n",
    "            x = x.view(-1,784)\n",
    "            y = y.view(-1)\n",
    "        elif model_type == 'CNN':\n",
    "            x = x.view(-1,1,28,28)\n",
    "            y = y.view(-1)\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "        loss = criterion(model(x), y)\n",
    "        n = y.size(0)\n",
    "        LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "        COUNTER += n\n",
    "    \n",
    "    return LOSSES / float(COUNTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 200: TRAIN 1.8038890406489372\n",
      " Iteration 400: TRAIN 0.45653281316161154\n",
      " Iteration 600: TRAIN 0.2718612297810614\n",
      " Iteration 800: TRAIN 0.21194624420255423\n",
      " Iteration 1000: TRAIN 0.1815738298540426\n",
      " [NLL] TRAIN 0.15185546285708745 / TEST 0.14618860087394714\n",
      " [ACC] TRAIN 0.95455 / TEST 0.9544\n",
      " Iteration 1200: TRAIN 0.14706243999302387\n",
      " Iteration 1400: TRAIN 0.13602764839306475\n",
      " Iteration 1600: TRAIN 0.12858284506946802\n",
      " Iteration 1800: TRAIN 0.11974911754950882\n",
      " Iteration 2000: TRAIN 0.10179303056165986\n",
      " [NLL] TRAIN 0.0982314137260119 / TEST 0.08828171434402465\n",
      " [ACC] TRAIN 0.9697666666666667 / TEST 0.9726\n",
      " Iteration 2200: TRAIN 0.09973444210365415\n",
      " Iteration 2400: TRAIN 0.09267908608540892\n",
      " Iteration 2600: TRAIN 0.09187613438814879\n",
      " Iteration 2800: TRAIN 0.09205739006400109\n",
      " Iteration 3000: TRAIN 0.07789612462496698\n",
      " [NLL] TRAIN 0.07731529317299525 / TEST 0.07236806674003601\n",
      " [ACC] TRAIN 0.9763666666666667 / TEST 0.978\n",
      " Iteration 3200: TRAIN 0.0873312658071518\n",
      " Iteration 3400: TRAIN 0.07623838745057583\n",
      " Iteration 3600: TRAIN 0.07500694574788212\n",
      " Iteration 3800: TRAIN 0.07048181453743077\n",
      " Iteration 4000: TRAIN 0.06758502749726177\n",
      " [NLL] TRAIN 0.07084563633600871 / TEST 0.06554578833580017\n",
      " [ACC] TRAIN 0.9780166666666666 / TEST 0.981\n",
      " Iteration 4200: TRAIN 0.06989576891064644\n",
      " Iteration 4400: TRAIN 0.064725532066077\n",
      " Iteration 4600: TRAIN 0.06717171413823962\n",
      " Iteration 4800: TRAIN 0.06468789525946281\n",
      " Iteration 5000: TRAIN 0.057835578229278324\n",
      " [NLL] TRAIN 0.061712598339716596 / TEST 0.059726653146743774\n",
      " [ACC] TRAIN 0.98145 / TEST 0.9822\n",
      " Iteration 5200: TRAIN 0.06482893539592624\n",
      " Iteration 5400: TRAIN 0.05856199637055397\n",
      " Iteration 5600: TRAIN 0.06023958023637533\n",
      " Iteration 5800: TRAIN 0.05854785330313489\n",
      " Iteration 6000: TRAIN 0.05758425395935774\n",
      " [NLL] TRAIN 0.05699623062213262 / TEST 0.053561259722709656\n",
      " [ACC] TRAIN 0.9828 / TEST 0.9827\n",
      " Iteration 6200: TRAIN 0.05618990732356906\n",
      " Iteration 6400: TRAIN 0.05652661118656397\n",
      " Iteration 6600: TRAIN 0.05576081256519882\n",
      " Iteration 6800: TRAIN 0.050444704033434394\n",
      " Iteration 7000: TRAIN 0.05649107176810503\n",
      " [NLL] TRAIN 0.05156157770554225 / TEST 0.052654201197624206\n",
      " [ACC] TRAIN 0.9849333333333333 / TEST 0.9822\n",
      " Iteration 7200: TRAIN 0.056084509771317244\n",
      " Iteration 7400: TRAIN 0.05155007604509592\n",
      " Iteration 7600: TRAIN 0.05058404588535017\n",
      " Iteration 7800: TRAIN 0.04906501907855272\n",
      " Iteration 8000: TRAIN 0.04740448389202356\n",
      " [NLL] TRAIN 0.050328088454405465 / TEST 0.04967133722305298\n",
      " [ACC] TRAIN 0.9847333333333333 / TEST 0.9835\n",
      " Iteration 8200: TRAIN 0.05335871377959847\n",
      " Iteration 8400: TRAIN 0.05206282150000334\n",
      " Iteration 8600: TRAIN 0.0522123357481825\n",
      " Iteration 8800: TRAIN 0.04653637768700719\n",
      " Iteration 9000: TRAIN 0.05079894378781319\n",
      " [NLL] TRAIN 0.04778228445847829 / TEST 0.047690158748626706\n",
      " [ACC] TRAIN 0.9862166666666666 / TEST 0.9842\n",
      " Iteration 9200: TRAIN 0.0485968379676342\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    \n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    ITERATIONS = 0\n",
    "    learning_curve_nll_train = list()\n",
    "    learning_curve_nll_test = list()\n",
    "    learning_curve_acc_train = list()\n",
    "    learning_curve_acc_test = list()\n",
    "    for e in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = batch\n",
    "            if model_type == 'MLP':\n",
    "                x = x.view(-1,784)\n",
    "                y = y.view(-1)\n",
    "            elif model_type == 'CNN':\n",
    "                x = x.view(-1,1,28,28)\n",
    "                y = y.view(-1)\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                \n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n = y.size(0)\n",
    "            LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "            COUNTER += n\n",
    "            ITERATIONS += 1\n",
    "            if ITERATIONS%(store_every/5) == 0:\n",
    "                avg_loss = LOSSES / float(COUNTER)\n",
    "                LOSSES = 0\n",
    "                COUNTER = 0\n",
    "                print(\" Iteration {}: TRAIN {}\".format(\n",
    "                    ITERATIONS, avg_loss))\n",
    "        \n",
    "            if ITERATIONS%(store_every) == 0:     \n",
    "                \n",
    "                train_loss = evaluate(train_loader, criterion)\n",
    "                learning_curve_nll_train.append(train_loss)\n",
    "                test_loss = evaluate(test_loader, criterion)\n",
    "                learning_curve_nll_test.append(test_loss)\n",
    "                \n",
    "                train_acc = evaluate(train_loader, accuracy)\n",
    "                learning_curve_acc_train.append(train_acc)\n",
    "                test_acc = evaluate(test_loader, accuracy)\n",
    "                learning_curve_acc_test.append(test_acc)\n",
    "                        \n",
    "                print(\" [NLL] TRAIN {} / TEST {}\".format(\n",
    "                    train_loss, test_loss))\n",
    "                print(\" [ACC] TRAIN {} / TEST {}\".format(\n",
    "                    train_acc, test_acc))\n",
    "        \n",
    "        adjust_lr(optimizer, e+1, num_epochs)\n",
    "        \n",
    "    return learning_curve_nll_train, \\\n",
    "           learning_curve_nll_test, \\\n",
    "           learning_curve_acc_train, \\\n",
    "           learning_curve_acc_test, \n",
    "           \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    _ = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
