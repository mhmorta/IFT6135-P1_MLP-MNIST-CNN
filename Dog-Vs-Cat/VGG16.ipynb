{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.Resize(224),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "#                                 normalize])\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "traindata = torchvision.datasets.ImageFolder('./data/trainset/', transform=transform)\n",
    "testset =torchvision.datasets.ImageFolder('./data/test/', transform=transform)\n",
    "\n",
    "\n",
    "size = [int(len(traindata)*0.9), len(traindata) - int(len(traindata)*0.9)]\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset=traindata, lengths=size)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                        batch_size=32,\n",
    "                                        shuffle=True)\n",
    "classes = ('Cat', 'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print (cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __all__ = [\n",
    "#     'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "#     'vgg19_bn', 'vgg19',\n",
    "# ]\n",
    "\n",
    "\n",
    "# model_urls = {\n",
    "#     'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "#     'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "#     'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "#     'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "#     'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "#     'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "#     'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "#     'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "# }\n",
    "\n",
    "\n",
    "# class VGG(nn.Module):\n",
    "\n",
    "#     def __init__(self, features, num_classes=10, init_weights=True):\n",
    "#         super(VGG, self).__init__()\n",
    "#         self.features = features\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(512 * 7 * 7, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "#         if init_weights:\n",
    "#             self._initialize_weights()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(-1, x.size(0))\n",
    "# #         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#                 if m.bias is not None:\n",
    "#                     m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 m.weight.data.normal_(0, 0.01)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "\n",
    "# def make_layers(cfg, batch_norm=False):\n",
    "#     layers = []\n",
    "#     in_channels = 3\n",
    "#     for v in cfg:\n",
    "#         if v == 'M':\n",
    "#             layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "#         else:\n",
    "#             conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "#             if batch_norm:\n",
    "#                 layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "#             else:\n",
    "#                 layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "#             in_channels = v\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# cfg = {\n",
    "#     'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "#     'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "#     'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "#     'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "# }\n",
    "\n",
    "\n",
    "# def vgg11(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg11_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg13(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 13-layer model (configuration \"B\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['B']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg13_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg16(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg16_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg19(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['E']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg19_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NNet, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             # Layaer 1\n",
    "#             nn.Conv2d(in_channels=3, out_channels=64,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#             # Layaer 3\n",
    "#             nn.Conv2d(in_channels=64, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#             # Layaer 5\n",
    "#             nn.Conv2d(in_channels=128, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#             nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#              # Layaer 8\n",
    "#             nn.Conv2d(in_channels=256, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "        \n",
    "#             # Layaer 11\n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),            \n",
    "#         )\n",
    "#         self.view(-1, 7*7*512)\n",
    "#         self.net = nn.Linear(7*7*512, 4096)\n",
    "#         self.net = nn.Linear(4096, 4096)\n",
    "#         self.net = nn.Linear(4096, 10)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         x = self.net(self.conv(x).squeeze())\n",
    "# #         x = x.view(-1, 7*7*512)\n",
    "# #         x = self.net = nn.Linear(7*7*512, 4096)\n",
    "# #         x = self.net = nn.Linear(4096, 4096)\n",
    "# #         x = self.net = nn.Linear(4096, 10)\n",
    "#         return self.net(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        # conv layers: (in_channel size, out_channels size, kernel_size, stride, padding)\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        # max pooling (kernel_size, stride)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully conected layers:\n",
    "        self.fc6 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 1000)\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 7 * 7 * 512)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = self.fc8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16(2)\n",
    "# net = vgg16()\n",
    "# net = NNet()\n",
    "learning_rate = 1e-3\n",
    "if cuda_available:\n",
    "    net.cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "            Conv2d-2         [-1, 64, 224, 224]          36,928\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "            Conv2d-5        [-1, 128, 112, 112]         147,584\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "            Conv2d-8          [-1, 256, 56, 56]         590,080\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "        MaxPool2d-10          [-1, 256, 28, 28]               0\n",
      "           Conv2d-11          [-1, 512, 28, 28]       1,180,160\n",
      "           Conv2d-12          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-13          [-1, 512, 28, 28]       2,359,808\n",
      "        MaxPool2d-14          [-1, 512, 14, 14]               0\n",
      "           Conv2d-15          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-16          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "        MaxPool2d-18            [-1, 512, 7, 7]               0\n",
      "           Linear-19                 [-1, 4096]     102,764,544\n",
      "           Linear-20                 [-1, 4096]      16,781,312\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 115.11\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 643.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 6.909 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-218480895c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "acc = []\n",
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        if cuda_available:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         print (images.shape)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "        \n",
    "        if batch_idx%50==0:\n",
    "            print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(validloader):\n",
    "        if cuda_available:\n",
    "            images, targets = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        accuracy = 100.*(correct/total)\n",
    "        acc.append(accuracy)\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print (learning_rate)\n",
    "    print('--------------------------------------------------------------')\n",
    "    net.train()\n",
    "    c += 1\n",
    "    if (c%5 == 0)  and (acc[epoch] <= min(acc[epoch-4:epoch-1])):\n",
    "        learning_rate *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
