{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "                                normalize])\n",
    "\n",
    "# transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "traindata = torchvision.datasets.ImageFolder('./Data/trainset/trainset/', transform=transform)\n",
    "testset =torchvision.datasets.ImageFolder('./Data/testset/', transform=transform)\n",
    "\n",
    "\n",
    "size = [int(len(traindata)*0.9), len(traindata) - int(len(traindata)*0.9)]\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset=traindata, lengths=size)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                        batch_size=32,\n",
    "                                        shuffle=True)\n",
    "classes = ('Cat', 'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print (cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __all__ = [\n",
    "#     'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "#     'vgg19_bn', 'vgg19',\n",
    "# ]\n",
    "\n",
    "\n",
    "# model_urls = {\n",
    "#     'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "#     'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "#     'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "#     'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "#     'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "#     'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "#     'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "#     'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "# }\n",
    "\n",
    "\n",
    "# class VGG(nn.Module):\n",
    "\n",
    "#     def __init__(self, features, num_classes=10, init_weights=True):\n",
    "#         super(VGG, self).__init__()\n",
    "#         self.features = features\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(512 * 7 * 7, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "#         if init_weights:\n",
    "#             self._initialize_weights()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(-1, x.size(0))\n",
    "# #         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#                 if m.bias is not None:\n",
    "#                     m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 m.weight.data.normal_(0, 0.01)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "\n",
    "# def make_layers(cfg, batch_norm=False):\n",
    "#     layers = []\n",
    "#     in_channels = 3\n",
    "#     for v in cfg:\n",
    "#         if v == 'M':\n",
    "#             layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "#         else:\n",
    "#             conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "#             if batch_norm:\n",
    "#                 layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "#             else:\n",
    "#                 layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "#             in_channels = v\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# cfg = {\n",
    "#     'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "#     'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "#     'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "#     'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "# }\n",
    "\n",
    "\n",
    "# def vgg11(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg11_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg13(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 13-layer model (configuration \"B\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['B']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg13_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg16(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg16_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg19(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['E']), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def vgg19_bn(pretrained=False, **kwargs):\n",
    "#     \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     if pretrained:\n",
    "#         kwargs['init_weights'] = False\n",
    "#     model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NNet, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             # Layaer 1\n",
    "#             nn.Conv2d(in_channels=3, out_channels=64,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#             # Layaer 3\n",
    "#             nn.Conv2d(in_channels=64, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#             # Layaer 5\n",
    "#             nn.Conv2d(in_channels=128, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#             nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "#              # Layaer 8\n",
    "#             nn.Conv2d(in_channels=256, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "        \n",
    "#             # Layaer 11\n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=2),            \n",
    "#         )\n",
    "#         self.view(-1, 7*7*512)\n",
    "#         self.net = nn.Linear(7*7*512, 4096)\n",
    "#         self.net = nn.Linear(4096, 4096)\n",
    "#         self.net = nn.Linear(4096, 10)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         x = self.net(self.conv(x).squeeze())\n",
    "# #         x = x.view(-1, 7*7*512)\n",
    "# #         x = self.net = nn.Linear(7*7*512, 4096)\n",
    "# #         x = self.net = nn.Linear(4096, 4096)\n",
    "# #         x = self.net = nn.Linear(4096, 10)\n",
    "#         return self.net(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        # conv layers: (in_channel size, out_channels size, kernel_size, stride, padding)\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        # max pooling (kernel_size, stride)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully conected layers:\n",
    "        self.fc6 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 1000)\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 7 * 7 * 512)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = self.fc8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16(2)\n",
    "# net = vgg16()\n",
    "# net = NNet()\n",
    "learning_rate = 1e-3\n",
    "if cuda_available:\n",
    "    net.cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "            Conv2d-2         [-1, 64, 224, 224]          36,928\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "            Conv2d-5        [-1, 128, 112, 112]         147,584\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "            Conv2d-8          [-1, 256, 56, 56]         590,080\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "        MaxPool2d-10          [-1, 256, 28, 28]               0\n",
      "           Conv2d-11          [-1, 512, 28, 28]       1,180,160\n",
      "           Conv2d-12          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-13          [-1, 512, 28, 28]       2,359,808\n",
      "        MaxPool2d-14          [-1, 512, 14, 14]               0\n",
      "           Conv2d-15          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-16          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "        MaxPool2d-18            [-1, 512, 7, 7]               0\n",
      "           Linear-19                 [-1, 4096]     102,764,544\n",
      "           Linear-20                 [-1, 4096]      16,781,312\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 115.11\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 643.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 6.904 \n",
      "Epoch : 0 Loss : 6.781 \n",
      "Epoch : 0 Loss : 6.602 \n",
      "Epoch : 0 Loss : 6.353 \n",
      "Epoch : 0 Loss : 5.306 \n",
      "Epoch : 0 Loss : 4.397 \n",
      "Epoch : 0 Loss : 3.788 \n",
      "Epoch : 0 Loss : 3.352 \n",
      "Epoch : 0 Loss : 3.023 \n",
      "Epoch : 0 Loss : 2.767 \n",
      "Epoch : 0 Loss : 2.564 \n",
      "Epoch : 0 Loss : 2.395 \n",
      "Epoch : 0 Loss : 2.257 \n",
      "Epoch : 0 Loss : 2.139 \n",
      "Epoch : 0 Loss : 2.039 \n",
      "Epoch : 0 Loss : 1.951 \n",
      "Epoch : 0 Loss : 1.875 \n",
      "Epoch : 0 Loss : 1.806 \n",
      "Epoch : 0 Loss : 1.746 \n",
      "Epoch : 0 Loss : 1.693 \n",
      "Epoch : 0 Loss : 1.644 \n",
      "Epoch : 0 Loss : 1.599 \n",
      "Epoch : 0 Loss : 1.559 \n",
      "Epoch : 0 Test Acc : 49.000\n",
      "0.001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 0.681 \n",
      "Epoch : 1 Loss : 0.704 \n",
      "Epoch : 1 Loss : 0.718 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.714 \n",
      "Epoch : 1 Loss : 0.715 \n",
      "Epoch : 1 Loss : 0.715 \n",
      "Epoch : 1 Loss : 0.715 \n",
      "Epoch : 1 Loss : 0.716 \n",
      "Epoch : 1 Loss : 0.715 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-218480895c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "acc = []\n",
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        if cuda_available:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         print (images.shape)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "        \n",
    "        if batch_idx%50==0:\n",
    "            print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(validloader):\n",
    "        if cuda_available:\n",
    "            images, targets = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        accuracy = 100.*(correct/total)\n",
    "        acc.append(accuracy)\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print (learning_rate)\n",
    "    print('--------------------------------------------------------------')\n",
    "    net.train()\n",
    "    c += 1\n",
    "    if (c%5 == 0)  and (acc[epoch] <= min(acc[epoch-4:epoch-1])):\n",
    "        learning_rate *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
