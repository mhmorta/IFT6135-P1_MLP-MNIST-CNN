{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/trainset/trainset/Cat/'\n",
    "list_images = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "traindata = torchvision.datasets.ImageFolder('./Data/trainset/trainset/', transform=transform)\n",
    "testset =torchvision.datasets.ImageFolder('./Data/testset/', transform=transform)\n",
    "\n",
    "\n",
    "size = [int(len(traindata)*0.9), len(traindata) - int(len(traindata)*0.9)]\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset=traindata, lengths=size)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                        batch_size=32,\n",
    "                                        shuffle=True)\n",
    "classes = ('Cat', 'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print (cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=16,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            # Layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            # Layer 6\n",
    "            nn.Conv2d(in_channels=128, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "             # Layer 7\n",
    "            nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            # Layer 8\n",
    "            nn.Conv2d(in_channels=256, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # Layer 9\n",
    "            nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3,3) , padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            \n",
    "        )\n",
    "        self.net = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NNet()\n",
    "learning_rate = 1e-4\n",
    "if cuda_available:\n",
    "    net.cuda()\n",
    "# optimizer = torch.optim.SGD(net.parameters(),lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 64, 64]             448\n",
      "       BatchNorm2d-2           [-1, 16, 64, 64]              32\n",
      "              ReLU-3           [-1, 16, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "              ReLU-6           [-1, 32, 64, 64]               0\n",
      "         MaxPool2d-7           [-1, 32, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          18,496\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]          73,856\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "             ReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "             ReLU-17          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-18            [-1, 128, 8, 8]               0\n",
      "           Conv2d-19            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-20            [-1, 256, 8, 8]             512\n",
      "             ReLU-21            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-22            [-1, 256, 4, 4]               0\n",
      "           Conv2d-23            [-1, 256, 4, 4]         590,080\n",
      "      BatchNorm2d-24            [-1, 256, 4, 4]             512\n",
      "             ReLU-25            [-1, 256, 4, 4]               0\n",
      "        MaxPool2d-26            [-1, 256, 2, 2]               0\n",
      "           Conv2d-27            [-1, 512, 2, 2]       1,180,160\n",
      "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-29            [-1, 512, 2, 2]               0\n",
      "           Conv2d-30            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-31            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-32            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-33            [-1, 512, 1, 1]               0\n",
      "           Linear-34                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 4,675,074\n",
      "Trainable params: 4,675,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 10.92\n",
      "Params size (MB): 17.83\n",
      "Estimated Total Size (MB): 28.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_decay(epoch, loss, lr):\n",
    "    mean_loss = np.mean(loss[epoch-10:epoch-1])\n",
    "    if np.float(loss[epoch]) <= np.float(mean_loss):\n",
    "        lr *= 0.1\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 0.682 \n",
      "Epoch : 0 Loss : 0.710 \n",
      "Epoch : 0 Loss : 0.673 \n",
      "Epoch : 0 Loss : 0.658 \n",
      "Epoch : 0 Loss : 0.646 \n",
      "Epoch : 0 Loss : 0.635 \n",
      "Epoch : 0 Loss : 0.622 \n",
      "Epoch : 0 Loss : 0.611 \n",
      "Epoch : 0 Loss : 0.597 \n",
      "Epoch : 0 Loss : 0.586 \n",
      "Epoch : 0 Loss : 0.575 \n",
      "Epoch : 0 Loss : 0.565 \n",
      "Epoch : 0 Test Acc : 81.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 0.440 \n",
      "Epoch : 1 Loss : 0.443 \n",
      "Epoch : 1 Loss : 0.434 \n",
      "Epoch : 1 Loss : 0.429 \n",
      "Epoch : 1 Loss : 0.417 \n",
      "Epoch : 1 Loss : 0.415 \n",
      "Epoch : 1 Loss : 0.409 \n",
      "Epoch : 1 Loss : 0.400 \n",
      "Epoch : 1 Loss : 0.396 \n",
      "Epoch : 1 Loss : 0.394 \n",
      "Epoch : 1 Loss : 0.392 \n",
      "Epoch : 1 Loss : 0.388 \n",
      "Epoch : 1 Test Acc : 82.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Loss : 0.452 \n",
      "Epoch : 2 Loss : 0.318 \n",
      "Epoch : 2 Loss : 0.315 \n",
      "Epoch : 2 Loss : 0.311 \n",
      "Epoch : 2 Loss : 0.308 \n",
      "Epoch : 2 Loss : 0.310 \n",
      "Epoch : 2 Loss : 0.314 \n",
      "Epoch : 2 Loss : 0.313 \n",
      "Epoch : 2 Loss : 0.311 \n",
      "Epoch : 2 Loss : 0.311 \n",
      "Epoch : 2 Loss : 0.311 \n",
      "Epoch : 2 Loss : 0.311 \n",
      "Epoch : 2 Test Acc : 88.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Loss : 0.204 \n",
      "Epoch : 3 Loss : 0.243 \n",
      "Epoch : 3 Loss : 0.261 \n",
      "Epoch : 3 Loss : 0.267 \n",
      "Epoch : 3 Loss : 0.268 \n",
      "Epoch : 3 Loss : 0.266 \n",
      "Epoch : 3 Loss : 0.262 \n",
      "Epoch : 3 Loss : 0.263 \n",
      "Epoch : 3 Loss : 0.259 \n",
      "Epoch : 3 Loss : 0.255 \n",
      "Epoch : 3 Loss : 0.255 \n",
      "Epoch : 3 Loss : 0.254 \n",
      "Epoch : 3 Test Acc : 88.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Loss : 0.065 \n",
      "Epoch : 4 Loss : 0.188 \n",
      "Epoch : 4 Loss : 0.200 \n",
      "Epoch : 4 Loss : 0.210 \n",
      "Epoch : 4 Loss : 0.210 \n",
      "Epoch : 4 Loss : 0.207 \n",
      "Epoch : 4 Loss : 0.211 \n",
      "Epoch : 4 Loss : 0.212 \n",
      "Epoch : 4 Loss : 0.211 \n",
      "Epoch : 4 Loss : 0.209 \n",
      "Epoch : 4 Loss : 0.207 \n",
      "Epoch : 4 Loss : 0.207 \n",
      "Epoch : 4 Test Acc : 87.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Loss : 0.168 \n",
      "Epoch : 5 Loss : 0.150 \n",
      "Epoch : 5 Loss : 0.158 \n",
      "Epoch : 5 Loss : 0.148 \n",
      "Epoch : 5 Loss : 0.156 \n",
      "Epoch : 5 Loss : 0.157 \n",
      "Epoch : 5 Loss : 0.158 \n",
      "Epoch : 5 Loss : 0.159 \n",
      "Epoch : 5 Loss : 0.163 \n",
      "Epoch : 5 Loss : 0.164 \n",
      "Epoch : 5 Loss : 0.165 \n",
      "Epoch : 5 Loss : 0.165 \n",
      "Epoch : 5 Test Acc : 87.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Loss : 0.176 \n",
      "Epoch : 6 Loss : 0.092 \n",
      "Epoch : 6 Loss : 0.105 \n",
      "Epoch : 6 Loss : 0.102 \n",
      "Epoch : 6 Loss : 0.105 \n",
      "Epoch : 6 Loss : 0.109 \n",
      "Epoch : 6 Loss : 0.115 \n",
      "Epoch : 6 Loss : 0.117 \n",
      "Epoch : 6 Loss : 0.117 \n",
      "Epoch : 6 Loss : 0.119 \n",
      "Epoch : 6 Loss : 0.119 \n",
      "Epoch : 6 Loss : 0.120 \n",
      "Epoch : 6 Test Acc : 88.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Loss : 0.045 \n",
      "Epoch : 7 Loss : 0.075 \n",
      "Epoch : 7 Loss : 0.078 \n",
      "Epoch : 7 Loss : 0.084 \n",
      "Epoch : 7 Loss : 0.083 \n",
      "Epoch : 7 Loss : 0.080 \n",
      "Epoch : 7 Loss : 0.082 \n",
      "Epoch : 7 Loss : 0.086 \n",
      "Epoch : 7 Loss : 0.089 \n",
      "Epoch : 7 Loss : 0.090 \n",
      "Epoch : 7 Loss : 0.091 \n",
      "Epoch : 7 Loss : 0.090 \n",
      "Epoch : 7 Test Acc : 90.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Loss : 0.092 \n",
      "Epoch : 8 Loss : 0.066 \n",
      "Epoch : 8 Loss : 0.061 \n",
      "Epoch : 8 Loss : 0.058 \n",
      "Epoch : 8 Loss : 0.061 \n",
      "Epoch : 8 Loss : 0.066 \n",
      "Epoch : 8 Loss : 0.064 \n",
      "Epoch : 8 Loss : 0.066 \n",
      "Epoch : 8 Loss : 0.067 \n",
      "Epoch : 8 Loss : 0.067 \n",
      "Epoch : 8 Loss : 0.068 \n",
      "Epoch : 8 Loss : 0.068 \n",
      "Epoch : 8 Test Acc : 87.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 9 Loss : 0.010 \n",
      "Epoch : 9 Loss : 0.056 \n",
      "Epoch : 9 Loss : 0.051 \n",
      "Epoch : 9 Loss : 0.047 \n",
      "Epoch : 9 Loss : 0.051 \n",
      "Epoch : 9 Loss : 0.052 \n",
      "Epoch : 9 Loss : 0.051 \n",
      "Epoch : 9 Loss : 0.052 \n",
      "Epoch : 9 Loss : 0.053 \n",
      "Epoch : 9 Loss : 0.055 \n",
      "Epoch : 9 Loss : 0.054 \n",
      "Epoch : 9 Loss : 0.054 \n",
      "Epoch : 9 Test Acc : 90.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 10 Loss : 0.100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laya/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/laya/.local/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 Loss : 0.042 \n",
      "Epoch : 10 Loss : 0.039 \n",
      "Epoch : 10 Loss : 0.041 \n",
      "Epoch : 10 Loss : 0.046 \n",
      "Epoch : 10 Loss : 0.043 \n",
      "Epoch : 10 Loss : 0.040 \n",
      "Epoch : 10 Loss : 0.043 \n",
      "Epoch : 10 Loss : 0.043 \n",
      "Epoch : 10 Loss : 0.043 \n",
      "Epoch : 10 Loss : 0.046 \n",
      "Epoch : 10 Loss : 0.047 \n",
      "Epoch : 10 Test Acc : 91.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 11 Loss : 0.009 \n",
      "Epoch : 11 Loss : 0.030 \n",
      "Epoch : 11 Loss : 0.028 \n",
      "Epoch : 11 Loss : 0.033 \n",
      "Epoch : 11 Loss : 0.032 \n",
      "Epoch : 11 Loss : 0.034 \n",
      "Epoch : 11 Loss : 0.034 \n",
      "Epoch : 11 Loss : 0.037 \n",
      "Epoch : 11 Loss : 0.037 \n",
      "Epoch : 11 Loss : 0.036 \n",
      "Epoch : 11 Loss : 0.036 \n",
      "Epoch : 11 Loss : 0.035 \n",
      "Epoch : 11 Test Acc : 87.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 12 Loss : 0.056 \n",
      "Epoch : 12 Loss : 0.042 \n",
      "Epoch : 12 Loss : 0.037 \n",
      "Epoch : 12 Loss : 0.035 \n",
      "Epoch : 12 Loss : 0.035 \n",
      "Epoch : 12 Loss : 0.036 \n",
      "Epoch : 12 Loss : 0.040 \n",
      "Epoch : 12 Loss : 0.036 \n",
      "Epoch : 12 Loss : 0.035 \n",
      "Epoch : 12 Loss : 0.036 \n",
      "Epoch : 12 Loss : 0.035 \n",
      "Epoch : 12 Loss : 0.036 \n",
      "Epoch : 12 Test Acc : 91.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 13 Loss : 0.011 \n",
      "Epoch : 13 Loss : 0.024 \n",
      "Epoch : 13 Loss : 0.022 \n",
      "Epoch : 13 Loss : 0.029 \n",
      "Epoch : 13 Loss : 0.030 \n",
      "Epoch : 13 Loss : 0.029 \n",
      "Epoch : 13 Loss : 0.028 \n",
      "Epoch : 13 Loss : 0.030 \n",
      "Epoch : 13 Loss : 0.029 \n",
      "Epoch : 13 Loss : 0.029 \n",
      "Epoch : 13 Loss : 0.028 \n",
      "Epoch : 13 Loss : 0.027 \n",
      "Epoch : 13 Test Acc : 86.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 14 Loss : 0.002 \n",
      "Epoch : 14 Loss : 0.025 \n",
      "Epoch : 14 Loss : 0.037 \n",
      "Epoch : 14 Loss : 0.033 \n",
      "Epoch : 14 Loss : 0.032 \n",
      "Epoch : 14 Loss : 0.029 \n",
      "Epoch : 14 Loss : 0.029 \n",
      "Epoch : 14 Loss : 0.030 \n",
      "Epoch : 14 Loss : 0.030 \n",
      "Epoch : 14 Loss : 0.029 \n",
      "Epoch : 14 Loss : 0.029 \n",
      "Epoch : 14 Loss : 0.030 \n",
      "Epoch : 14 Test Acc : 89.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 15 Loss : 0.063 \n",
      "Epoch : 15 Loss : 0.024 \n",
      "Epoch : 15 Loss : 0.018 \n",
      "Epoch : 15 Loss : 0.018 \n",
      "Epoch : 15 Loss : 0.019 \n",
      "Epoch : 15 Loss : 0.024 \n",
      "Epoch : 15 Loss : 0.026 \n",
      "Epoch : 15 Loss : 0.026 \n",
      "Epoch : 15 Loss : 0.028 \n",
      "Epoch : 15 Loss : 0.032 \n",
      "Epoch : 15 Loss : 0.031 \n",
      "Epoch : 15 Loss : 0.030 \n",
      "Epoch : 15 Test Acc : 90.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 16 Loss : 0.000 \n",
      "Epoch : 16 Loss : 0.010 \n",
      "Epoch : 16 Loss : 0.017 \n",
      "Epoch : 16 Loss : 0.020 \n",
      "Epoch : 16 Loss : 0.022 \n",
      "Epoch : 16 Loss : 0.021 \n",
      "Epoch : 16 Loss : 0.019 \n",
      "Epoch : 16 Loss : 0.018 \n",
      "Epoch : 16 Loss : 0.018 \n",
      "Epoch : 16 Loss : 0.019 \n",
      "Epoch : 16 Loss : 0.019 \n",
      "Epoch : 16 Loss : 0.021 \n",
      "Epoch : 16 Test Acc : 90.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 17 Loss : 0.095 \n",
      "Epoch : 17 Loss : 0.038 \n",
      "Epoch : 17 Loss : 0.032 \n",
      "Epoch : 17 Loss : 0.027 \n",
      "Epoch : 17 Loss : 0.024 \n",
      "Epoch : 17 Loss : 0.022 \n",
      "Epoch : 17 Loss : 0.024 \n",
      "Epoch : 17 Loss : 0.023 \n",
      "Epoch : 17 Loss : 0.024 \n",
      "Epoch : 17 Loss : 0.024 \n",
      "Epoch : 17 Loss : 0.022 \n",
      "Epoch : 17 Loss : 0.021 \n",
      "Epoch : 17 Test Acc : 89.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 18 Loss : 0.001 \n",
      "Epoch : 18 Loss : 0.020 \n",
      "Epoch : 18 Loss : 0.018 \n",
      "Epoch : 18 Loss : 0.020 \n",
      "Epoch : 18 Loss : 0.019 \n",
      "Epoch : 18 Loss : 0.018 \n",
      "Epoch : 18 Loss : 0.019 \n",
      "Epoch : 18 Loss : 0.020 \n",
      "Epoch : 18 Loss : 0.021 \n",
      "Epoch : 18 Loss : 0.021 \n",
      "Epoch : 18 Loss : 0.021 \n",
      "Epoch : 18 Loss : 0.022 \n",
      "Epoch : 18 Test Acc : 88.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 19 Loss : 0.022 \n",
      "Epoch : 19 Loss : 0.029 \n",
      "Epoch : 19 Loss : 0.022 \n",
      "Epoch : 19 Loss : 0.019 \n",
      "Epoch : 19 Loss : 0.018 \n",
      "Epoch : 19 Loss : 0.017 \n",
      "Epoch : 19 Loss : 0.016 \n",
      "Epoch : 19 Loss : 0.017 \n",
      "Epoch : 19 Loss : 0.016 \n",
      "Epoch : 19 Loss : 0.016 \n",
      "Epoch : 19 Loss : 0.018 \n",
      "Epoch : 19 Loss : 0.020 \n",
      "Epoch : 19 Test Acc : 90.000\n",
      "0.0001\n",
      "--------------------------------------------------------------\n",
      "Epoch : 20 Loss : 0.007 \n",
      "Epoch : 20 Loss : 0.022 \n",
      "Epoch : 20 Loss : 0.014 \n",
      "Epoch : 20 Loss : 0.011 \n",
      "Epoch : 20 Loss : 0.010 \n",
      "Epoch : 20 Loss : 0.010 \n",
      "Epoch : 20 Loss : 0.012 \n",
      "Epoch : 20 Loss : 0.015 \n",
      "Epoch : 20 Loss : 0.016 \n",
      "Epoch : 20 Loss : 0.016 \n",
      "Epoch : 20 Loss : 0.016 \n",
      "Epoch : 20 Loss : 0.018 \n",
      "Epoch : 20 Test Acc : 89.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 21 Loss : 0.026 \n",
      "Epoch : 21 Loss : 0.021 \n",
      "Epoch : 21 Loss : 0.018 \n",
      "Epoch : 21 Loss : 0.017 \n",
      "Epoch : 21 Loss : 0.019 \n",
      "Epoch : 21 Loss : 0.017 \n",
      "Epoch : 21 Loss : 0.017 \n",
      "Epoch : 21 Loss : 0.018 \n",
      "Epoch : 21 Loss : 0.019 \n",
      "Epoch : 21 Loss : 0.018 \n",
      "Epoch : 21 Loss : 0.017 \n",
      "Epoch : 21 Loss : 0.018 \n",
      "Epoch : 21 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 22 Loss : 0.003 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.014 \n",
      "Epoch : 22 Loss : 0.015 \n",
      "Epoch : 22 Loss : 0.018 \n",
      "Epoch : 22 Loss : 0.018 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.017 \n",
      "Epoch : 22 Loss : 0.018 \n",
      "Epoch : 22 Test Acc : 91.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 23 Loss : 0.001 \n",
      "Epoch : 23 Loss : 0.010 \n",
      "Epoch : 23 Loss : 0.009 \n",
      "Epoch : 23 Loss : 0.010 \n",
      "Epoch : 23 Loss : 0.011 \n",
      "Epoch : 23 Loss : 0.011 \n",
      "Epoch : 23 Loss : 0.013 \n",
      "Epoch : 23 Loss : 0.014 \n",
      "Epoch : 23 Loss : 0.013 \n",
      "Epoch : 23 Loss : 0.013 \n",
      "Epoch : 23 Loss : 0.012 \n",
      "Epoch : 23 Loss : 0.012 \n",
      "Epoch : 23 Test Acc : 89.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 24 Loss : 0.119 \n",
      "Epoch : 24 Loss : 0.027 \n",
      "Epoch : 24 Loss : 0.021 \n",
      "Epoch : 24 Loss : 0.018 \n",
      "Epoch : 24 Loss : 0.020 \n",
      "Epoch : 24 Loss : 0.018 \n",
      "Epoch : 24 Loss : 0.016 \n",
      "Epoch : 24 Loss : 0.016 \n",
      "Epoch : 24 Loss : 0.017 \n",
      "Epoch : 24 Loss : 0.021 \n",
      "Epoch : 24 Loss : 0.021 \n",
      "Epoch : 24 Loss : 0.020 \n",
      "Epoch : 24 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 25 Loss : 0.075 \n",
      "Epoch : 25 Loss : 0.014 \n",
      "Epoch : 25 Loss : 0.017 \n",
      "Epoch : 25 Loss : 0.017 \n",
      "Epoch : 25 Loss : 0.016 \n",
      "Epoch : 25 Loss : 0.015 \n",
      "Epoch : 25 Loss : 0.014 \n",
      "Epoch : 25 Loss : 0.013 \n",
      "Epoch : 25 Loss : 0.013 \n",
      "Epoch : 25 Loss : 0.012 \n",
      "Epoch : 25 Loss : 0.013 \n",
      "Epoch : 25 Loss : 0.015 \n",
      "Epoch : 25 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 26 Loss : 0.001 \n",
      "Epoch : 26 Loss : 0.015 \n",
      "Epoch : 26 Loss : 0.013 \n",
      "Epoch : 26 Loss : 0.014 \n",
      "Epoch : 26 Loss : 0.015 \n",
      "Epoch : 26 Loss : 0.013 \n",
      "Epoch : 26 Loss : 0.012 \n",
      "Epoch : 26 Loss : 0.012 \n",
      "Epoch : 26 Loss : 0.013 \n",
      "Epoch : 26 Loss : 0.015 \n",
      "Epoch : 26 Loss : 0.015 \n",
      "Epoch : 26 Loss : 0.015 \n",
      "Epoch : 26 Test Acc : 89.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 27 Loss : 0.008 \n",
      "Epoch : 27 Loss : 0.012 \n",
      "Epoch : 27 Loss : 0.008 \n",
      "Epoch : 27 Loss : 0.008 \n",
      "Epoch : 27 Loss : 0.007 \n",
      "Epoch : 27 Loss : 0.008 \n",
      "Epoch : 27 Loss : 0.010 \n",
      "Epoch : 27 Loss : 0.011 \n",
      "Epoch : 27 Loss : 0.011 \n",
      "Epoch : 27 Loss : 0.012 \n",
      "Epoch : 27 Loss : 0.011 \n",
      "Epoch : 27 Loss : 0.010 \n",
      "Epoch : 27 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 28 Loss : 0.002 \n",
      "Epoch : 28 Loss : 0.014 \n",
      "Epoch : 28 Loss : 0.014 \n",
      "Epoch : 28 Loss : 0.012 \n",
      "Epoch : 28 Loss : 0.011 \n",
      "Epoch : 28 Loss : 0.012 \n",
      "Epoch : 28 Loss : 0.013 \n",
      "Epoch : 28 Loss : 0.014 \n",
      "Epoch : 28 Loss : 0.014 \n",
      "Epoch : 28 Loss : 0.016 \n",
      "Epoch : 28 Loss : 0.016 \n",
      "Epoch : 28 Loss : 0.015 \n",
      "Epoch : 28 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 29 Loss : 0.002 \n",
      "Epoch : 29 Loss : 0.012 \n",
      "Epoch : 29 Loss : 0.009 \n",
      "Epoch : 29 Loss : 0.008 \n",
      "Epoch : 29 Loss : 0.008 \n",
      "Epoch : 29 Loss : 0.011 \n",
      "Epoch : 29 Loss : 0.012 \n",
      "Epoch : 29 Loss : 0.012 \n",
      "Epoch : 29 Loss : 0.013 \n",
      "Epoch : 29 Loss : 0.014 \n",
      "Epoch : 29 Loss : 0.014 \n",
      "Epoch : 29 Loss : 0.014 \n",
      "Epoch : 29 Test Acc : 90.000\n",
      "1e-05\n",
      "--------------------------------------------------------------\n",
      "Epoch : 30 Loss : 0.001 \n",
      "Epoch : 30 Loss : 0.013 \n",
      "Epoch : 30 Loss : 0.011 \n",
      "Epoch : 30 Loss : 0.009 \n",
      "Epoch : 30 Loss : 0.009 \n",
      "Epoch : 30 Loss : 0.008 \n",
      "Epoch : 30 Loss : 0.009 \n",
      "Epoch : 30 Loss : 0.010 \n",
      "Epoch : 30 Loss : 0.011 \n",
      "Epoch : 30 Loss : 0.012 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30 Loss : 0.012 \n",
      "Epoch : 30 Loss : 0.012 \n",
      "Epoch : 30 Test Acc : 89.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 31 Loss : 0.000 \n",
      "Epoch : 31 Loss : 0.010 \n",
      "Epoch : 31 Loss : 0.007 \n",
      "Epoch : 31 Loss : 0.006 \n",
      "Epoch : 31 Loss : 0.008 \n",
      "Epoch : 31 Loss : 0.008 \n",
      "Epoch : 31 Loss : 0.008 \n",
      "Epoch : 31 Loss : 0.009 \n",
      "Epoch : 31 Loss : 0.010 \n",
      "Epoch : 31 Loss : 0.010 \n",
      "Epoch : 31 Loss : 0.009 \n",
      "Epoch : 31 Loss : 0.009 \n",
      "Epoch : 31 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 32 Loss : 0.000 \n",
      "Epoch : 32 Loss : 0.011 \n",
      "Epoch : 32 Loss : 0.017 \n",
      "Epoch : 32 Loss : 0.013 \n",
      "Epoch : 32 Loss : 0.011 \n",
      "Epoch : 32 Loss : 0.010 \n",
      "Epoch : 32 Loss : 0.011 \n",
      "Epoch : 32 Loss : 0.009 \n",
      "Epoch : 32 Loss : 0.009 \n",
      "Epoch : 32 Loss : 0.009 \n",
      "Epoch : 32 Loss : 0.008 \n",
      "Epoch : 32 Loss : 0.008 \n",
      "Epoch : 32 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 33 Loss : 0.000 \n",
      "Epoch : 33 Loss : 0.002 \n",
      "Epoch : 33 Loss : 0.004 \n",
      "Epoch : 33 Loss : 0.014 \n",
      "Epoch : 33 Loss : 0.017 \n",
      "Epoch : 33 Loss : 0.018 \n",
      "Epoch : 33 Loss : 0.017 \n",
      "Epoch : 33 Loss : 0.016 \n",
      "Epoch : 33 Loss : 0.016 \n",
      "Epoch : 33 Loss : 0.016 \n",
      "Epoch : 33 Loss : 0.016 \n",
      "Epoch : 33 Loss : 0.015 \n",
      "Epoch : 33 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 34 Loss : 0.001 \n",
      "Epoch : 34 Loss : 0.004 \n",
      "Epoch : 34 Loss : 0.007 \n",
      "Epoch : 34 Loss : 0.008 \n",
      "Epoch : 34 Loss : 0.007 \n",
      "Epoch : 34 Loss : 0.010 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Loss : 0.011 \n",
      "Epoch : 34 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 35 Loss : 0.000 \n",
      "Epoch : 35 Loss : 0.002 \n",
      "Epoch : 35 Loss : 0.004 \n",
      "Epoch : 35 Loss : 0.012 \n",
      "Epoch : 35 Loss : 0.012 \n",
      "Epoch : 35 Loss : 0.012 \n",
      "Epoch : 35 Loss : 0.012 \n",
      "Epoch : 35 Loss : 0.011 \n",
      "Epoch : 35 Loss : 0.011 \n",
      "Epoch : 35 Loss : 0.010 \n",
      "Epoch : 35 Loss : 0.012 \n",
      "Epoch : 35 Loss : 0.013 \n",
      "Epoch : 35 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 36 Loss : 0.006 \n",
      "Epoch : 36 Loss : 0.008 \n",
      "Epoch : 36 Loss : 0.007 \n",
      "Epoch : 36 Loss : 0.006 \n",
      "Epoch : 36 Loss : 0.006 \n",
      "Epoch : 36 Loss : 0.007 \n",
      "Epoch : 36 Loss : 0.007 \n",
      "Epoch : 36 Loss : 0.007 \n",
      "Epoch : 36 Loss : 0.009 \n",
      "Epoch : 36 Loss : 0.010 \n",
      "Epoch : 36 Loss : 0.009 \n",
      "Epoch : 36 Loss : 0.009 \n",
      "Epoch : 36 Test Acc : 89.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 37 Loss : 0.000 \n",
      "Epoch : 37 Loss : 0.019 \n",
      "Epoch : 37 Loss : 0.013 \n",
      "Epoch : 37 Loss : 0.012 \n",
      "Epoch : 37 Loss : 0.010 \n",
      "Epoch : 37 Loss : 0.008 \n",
      "Epoch : 37 Loss : 0.012 \n",
      "Epoch : 37 Loss : 0.013 \n",
      "Epoch : 37 Loss : 0.012 \n",
      "Epoch : 37 Loss : 0.013 \n",
      "Epoch : 37 Loss : 0.013 \n",
      "Epoch : 37 Loss : 0.013 \n",
      "Epoch : 37 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 38 Loss : 0.049 \n",
      "Epoch : 38 Loss : 0.004 \n",
      "Epoch : 38 Loss : 0.003 \n",
      "Epoch : 38 Loss : 0.004 \n",
      "Epoch : 38 Loss : 0.008 \n",
      "Epoch : 38 Loss : 0.009 \n",
      "Epoch : 38 Loss : 0.009 \n",
      "Epoch : 38 Loss : 0.012 \n",
      "Epoch : 38 Loss : 0.012 \n",
      "Epoch : 38 Loss : 0.014 \n",
      "Epoch : 38 Loss : 0.013 \n",
      "Epoch : 38 Loss : 0.013 \n",
      "Epoch : 38 Test Acc : 91.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 39 Loss : 0.002 \n",
      "Epoch : 39 Loss : 0.006 \n",
      "Epoch : 39 Loss : 0.006 \n",
      "Epoch : 39 Loss : 0.008 \n",
      "Epoch : 39 Loss : 0.009 \n",
      "Epoch : 39 Loss : 0.010 \n",
      "Epoch : 39 Loss : 0.010 \n",
      "Epoch : 39 Loss : 0.010 \n",
      "Epoch : 39 Loss : 0.010 \n",
      "Epoch : 39 Loss : 0.011 \n",
      "Epoch : 39 Loss : 0.011 \n",
      "Epoch : 39 Loss : 0.011 \n",
      "Epoch : 39 Test Acc : 90.000\n",
      "1.0000000000000002e-06\n",
      "--------------------------------------------------------------\n",
      "Epoch : 40 Loss : 0.002 \n",
      "Epoch : 40 Loss : 0.005 \n",
      "Epoch : 40 Loss : 0.004 \n",
      "Epoch : 40 Loss : 0.004 \n",
      "Epoch : 40 Loss : 0.004 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Loss : 0.003 \n",
      "Epoch : 40 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 41 Loss : 0.011 \n",
      "Epoch : 41 Loss : 0.003 \n",
      "Epoch : 41 Loss : 0.007 \n",
      "Epoch : 41 Loss : 0.016 \n",
      "Epoch : 41 Loss : 0.015 \n",
      "Epoch : 41 Loss : 0.014 \n",
      "Epoch : 41 Loss : 0.014 \n",
      "Epoch : 41 Loss : 0.013 \n",
      "Epoch : 41 Loss : 0.012 \n",
      "Epoch : 41 Loss : 0.012 \n",
      "Epoch : 41 Loss : 0.012 \n",
      "Epoch : 41 Loss : 0.012 \n",
      "Epoch : 41 Test Acc : 91.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 42 Loss : 0.002 \n",
      "Epoch : 42 Loss : 0.004 \n",
      "Epoch : 42 Loss : 0.004 \n",
      "Epoch : 42 Loss : 0.003 \n",
      "Epoch : 42 Loss : 0.004 \n",
      "Epoch : 42 Loss : 0.005 \n",
      "Epoch : 42 Loss : 0.007 \n",
      "Epoch : 42 Loss : 0.008 \n",
      "Epoch : 42 Loss : 0.008 \n",
      "Epoch : 42 Loss : 0.009 \n",
      "Epoch : 42 Loss : 0.009 \n",
      "Epoch : 42 Loss : 0.010 \n",
      "Epoch : 42 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 43 Loss : 0.005 \n",
      "Epoch : 43 Loss : 0.006 \n",
      "Epoch : 43 Loss : 0.008 \n",
      "Epoch : 43 Loss : 0.008 \n",
      "Epoch : 43 Loss : 0.010 \n",
      "Epoch : 43 Loss : 0.009 \n",
      "Epoch : 43 Loss : 0.008 \n",
      "Epoch : 43 Loss : 0.008 \n",
      "Epoch : 43 Loss : 0.007 \n",
      "Epoch : 43 Loss : 0.007 \n",
      "Epoch : 43 Loss : 0.007 \n",
      "Epoch : 43 Loss : 0.008 \n",
      "Epoch : 43 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 44 Loss : 0.001 \n",
      "Epoch : 44 Loss : 0.018 \n",
      "Epoch : 44 Loss : 0.014 \n",
      "Epoch : 44 Loss : 0.011 \n",
      "Epoch : 44 Loss : 0.010 \n",
      "Epoch : 44 Loss : 0.009 \n",
      "Epoch : 44 Loss : 0.009 \n",
      "Epoch : 44 Loss : 0.009 \n",
      "Epoch : 44 Loss : 0.009 \n",
      "Epoch : 44 Loss : 0.008 \n",
      "Epoch : 44 Loss : 0.008 \n",
      "Epoch : 44 Loss : 0.008 \n",
      "Epoch : 44 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 45 Loss : 0.001 \n",
      "Epoch : 45 Loss : 0.008 \n",
      "Epoch : 45 Loss : 0.007 \n",
      "Epoch : 45 Loss : 0.007 \n",
      "Epoch : 45 Loss : 0.008 \n",
      "Epoch : 45 Loss : 0.011 \n",
      "Epoch : 45 Loss : 0.010 \n",
      "Epoch : 45 Loss : 0.009 \n",
      "Epoch : 45 Loss : 0.010 \n",
      "Epoch : 45 Loss : 0.010 \n",
      "Epoch : 45 Loss : 0.010 \n",
      "Epoch : 45 Loss : 0.011 \n",
      "Epoch : 45 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 46 Loss : 0.046 \n",
      "Epoch : 46 Loss : 0.005 \n",
      "Epoch : 46 Loss : 0.005 \n",
      "Epoch : 46 Loss : 0.005 \n",
      "Epoch : 46 Loss : 0.004 \n",
      "Epoch : 46 Loss : 0.004 \n",
      "Epoch : 46 Loss : 0.004 \n",
      "Epoch : 46 Loss : 0.003 \n",
      "Epoch : 46 Loss : 0.003 \n",
      "Epoch : 46 Loss : 0.004 \n",
      "Epoch : 46 Loss : 0.005 \n",
      "Epoch : 46 Loss : 0.006 \n",
      "Epoch : 46 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 47 Loss : 0.019 \n",
      "Epoch : 47 Loss : 0.007 \n",
      "Epoch : 47 Loss : 0.008 \n",
      "Epoch : 47 Loss : 0.007 \n",
      "Epoch : 47 Loss : 0.006 \n",
      "Epoch : 47 Loss : 0.006 \n",
      "Epoch : 47 Loss : 0.008 \n",
      "Epoch : 47 Loss : 0.009 \n",
      "Epoch : 47 Loss : 0.009 \n",
      "Epoch : 47 Loss : 0.009 \n",
      "Epoch : 47 Loss : 0.009 \n",
      "Epoch : 47 Loss : 0.009 \n",
      "Epoch : 47 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 48 Loss : 0.001 \n",
      "Epoch : 48 Loss : 0.005 \n",
      "Epoch : 48 Loss : 0.005 \n",
      "Epoch : 48 Loss : 0.006 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.007 \n",
      "Epoch : 48 Loss : 0.006 \n",
      "Epoch : 48 Test Acc : 90.000\n",
      "1.0000000000000002e-07\n",
      "--------------------------------------------------------------\n",
      "Epoch : 49 Loss : 0.000 \n",
      "Epoch : 49 Loss : 0.014 \n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "acc_val = []\n",
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        if cuda_available:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "        \n",
    "        if batch_idx%50==0:\n",
    "            print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(validloader):\n",
    "        if cuda_available:\n",
    "            images, targets = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        accuracy = 100.*(correct/total)\n",
    "        acc_val.append(accuracy)\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print (learning_rate)\n",
    "    print('--------------------------------------------------------------')\n",
    "    net.train()\n",
    "    c += 1\n",
    "    if (c%10 == 0):\n",
    "        learning_rate = learning_rate_decay(epoch, acc_val, learning_rate)\n",
    "#     if (c%10 == 0)  and (acc_val[epoch] <= min(acc_val[epoch-4:epoch-1])):\n",
    "#         learning_rate *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './model/adam.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), \n",
    "#            os.path.join('saved_model', 'cnnT1_epoch_{}_iter_{}_loss_{}_acc_{}_{}.t7'.format(epoch + 1, i,\n",
    "#            last_loss, acc, datetime.datetime.now().strftime(\"%b_%d_%H:%M:%S\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_image = trainset[0\n",
    "# img = torch.from_numpy(np_image)\n",
    "# img = img.view(img.shape[1], img.shape[2], img.shape[0])\n",
    "# # img = img / 2+0.5\n",
    "# # npimg = img.numpy()\n",
    "# # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
