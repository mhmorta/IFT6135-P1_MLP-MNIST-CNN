{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "# import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchvision.datasets.folder.ImageFolder object at 0x7f0809188828>\n",
      "<torchvision.datasets.folder.ImageFolder object at 0x7f0809188a58>\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(\n",
    "                    root='./data/trainset/',\n",
    "                    transform=transforms\n",
    "                    )\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "                    root= './data/test/', \n",
    "                    transform=transforms)\n",
    "\n",
    "dataset_ratio = np.array([95, 5])/100\n",
    "\n",
    "sizes = [int(x*len(data)) for x in dataset_ratio]\n",
    "sizes[0] += len(data) - sum(sizes)\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=data, lengths=sizes)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=False\n",
    "                    )\n",
    "print(data)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "lr0 = 0.002\n",
    "optim = 'adam'\n",
    "num_epochs = 10\n",
    "store_every = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a residual convolution block to be used in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1, activation = nn.ReLU):\n",
    "        super(ResidualConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu1 = nn.ReLU(in_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu2 = nn.ReLU(in_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "#             self.projected_conv = self.conv1x1(in_channels, out_channels)\n",
    "            self.project_linear = nn.Linear(in_channels, out_channels)\n",
    "    def forward(x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.in_channels == self.out_channels:\n",
    "            out += identity\n",
    "        else:\n",
    "            out += self.project_linear(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "    def conv1x1(in_channels, out_channels, stride=1):\n",
    "        \"\"\"1x1 convolution\"\"\"\n",
    "        print()\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            ResidualConv(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            ResidualConv(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            ResidualConv(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(64, 2)\n",
    "        \n",
    "        def forward(x):\n",
    "            return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanilaCNN(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(VanilaCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 6\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanilaCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU()\n",
      "    (17): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 64, 64]             448\n",
      "              ReLU-2           [-1, 16, 64, 64]               0\n",
      "         MaxPool2d-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]           4,640\n",
      "              ReLU-5           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-6           [-1, 32, 16, 16]               0\n",
      "            Conv2d-7           [-1, 64, 16, 16]          18,496\n",
      "              ReLU-8           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-9             [-1, 64, 8, 8]               0\n",
      "           Conv2d-10            [-1, 128, 8, 8]          73,856\n",
      "             ReLU-11            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-12            [-1, 128, 4, 4]               0\n",
      "           Conv2d-13            [-1, 128, 4, 4]         147,584\n",
      "             ReLU-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "           Conv2d-16            [-1, 256, 2, 2]         295,168\n",
      "             ReLU-17            [-1, 256, 2, 2]               0\n",
      "        MaxPool2d-18            [-1, 256, 1, 1]               0\n",
      "           Linear-19                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 540,706\n",
      "Trainable params: 540,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.16\n",
      "Params size (MB): 2.06\n",
      "Estimated Total Size (MB): 4.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "source": [
    "## Second implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "if cuda_available:\n",
    "    clf = clf.cuda()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 0.950 \n",
      "Epoch : 0 Loss : 0.704 \n",
      "Epoch : 0 Loss : 0.659 \n",
      "Epoch : 0 Loss : 0.637 \n",
      "Epoch : 0 Loss : 0.616 \n",
      "Epoch : 0 Test Acc : 71.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 0.578 \n",
      "Epoch : 1 Loss : 0.514 \n",
      "Epoch : 1 Loss : 0.505 \n",
      "Epoch : 1 Loss : 0.506 \n",
      "Epoch : 1 Loss : 0.504 \n",
      "Epoch : 1 Test Acc : 75.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Loss : 0.435 \n",
      "Epoch : 2 Loss : 0.426 \n",
      "Epoch : 2 Loss : 0.430 \n",
      "Epoch : 2 Loss : 0.432 \n",
      "Epoch : 2 Loss : 0.434 \n",
      "Epoch : 2 Test Acc : 75.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Loss : 0.384 \n",
      "Epoch : 3 Loss : 0.370 \n",
      "Epoch : 3 Loss : 0.374 \n",
      "Epoch : 3 Loss : 0.374 \n",
      "Epoch : 3 Loss : 0.371 \n",
      "Epoch : 3 Test Acc : 76.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Loss : 0.353 \n",
      "Epoch : 4 Loss : 0.327 \n",
      "Epoch : 4 Loss : 0.327 \n",
      "Epoch : 4 Loss : 0.333 \n",
      "Epoch : 4 Loss : 0.338 \n",
      "Epoch : 4 Test Acc : 75.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Loss : 0.372 \n",
      "Epoch : 5 Loss : 0.273 \n",
      "Epoch : 5 Loss : 0.281 \n",
      "Epoch : 5 Loss : 0.283 \n",
      "Epoch : 5 Loss : 0.290 \n",
      "Epoch : 5 Test Acc : 77.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Loss : 0.256 \n",
      "Epoch : 6 Loss : 0.253 \n",
      "Epoch : 6 Loss : 0.254 \n",
      "Epoch : 6 Loss : 0.249 \n",
      "Epoch : 6 Loss : 0.249 \n",
      "Epoch : 6 Test Acc : 75.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Loss : 0.172 \n",
      "Epoch : 7 Loss : 0.202 \n",
      "Epoch : 7 Loss : 0.197 \n",
      "Epoch : 7 Loss : 0.201 \n",
      "Epoch : 7 Loss : 0.210 \n",
      "Epoch : 7 Test Acc : 73.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Loss : 0.205 \n",
      "Epoch : 8 Loss : 0.177 \n",
      "Epoch : 8 Loss : 0.172 \n",
      "Epoch : 8 Loss : 0.174 \n",
      "Epoch : 8 Loss : 0.183 \n",
      "Epoch : 8 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 9 Loss : 0.096 \n",
      "Epoch : 9 Loss : 0.129 \n",
      "Epoch : 9 Loss : 0.124 \n",
      "Epoch : 9 Loss : 0.129 \n",
      "Epoch : 9 Loss : 0.135 \n",
      "Epoch : 9 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 10 Loss : 0.086 \n",
      "Epoch : 10 Loss : 0.103 \n",
      "Epoch : 10 Loss : 0.106 \n",
      "Epoch : 10 Loss : 0.107 \n",
      "Epoch : 10 Loss : 0.108 \n",
      "Epoch : 10 Test Acc : 76.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 11 Loss : 0.049 \n",
      "Epoch : 11 Loss : 0.100 \n",
      "Epoch : 11 Loss : 0.100 \n",
      "Epoch : 11 Loss : 0.100 \n",
      "Epoch : 11 Loss : 0.105 \n",
      "Epoch : 11 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 12 Loss : 0.062 \n",
      "Epoch : 12 Loss : 0.074 \n",
      "Epoch : 12 Loss : 0.073 \n",
      "Epoch : 12 Loss : 0.072 \n",
      "Epoch : 12 Loss : 0.079 \n",
      "Epoch : 12 Test Acc : 74.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 13 Loss : 0.157 \n",
      "Epoch : 13 Loss : 0.106 \n",
      "Epoch : 13 Loss : 0.086 \n",
      "Epoch : 13 Loss : 0.079 \n",
      "Epoch : 13 Loss : 0.079 \n",
      "Epoch : 13 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 14 Loss : 0.033 \n",
      "Epoch : 14 Loss : 0.048 \n",
      "Epoch : 14 Loss : 0.047 \n",
      "Epoch : 14 Loss : 0.047 \n",
      "Epoch : 14 Loss : 0.047 \n",
      "Epoch : 14 Test Acc : 76.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 15 Loss : 0.048 \n",
      "Epoch : 15 Loss : 0.039 \n",
      "Epoch : 15 Loss : 0.036 \n",
      "Epoch : 15 Loss : 0.034 \n",
      "Epoch : 15 Loss : 0.034 \n",
      "Epoch : 15 Test Acc : 75.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 16 Loss : 0.082 \n",
      "Epoch : 16 Loss : 0.045 \n",
      "Epoch : 16 Loss : 0.037 \n",
      "Epoch : 16 Loss : 0.035 \n",
      "Epoch : 16 Loss : 0.034 \n",
      "Epoch : 16 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 17 Loss : 0.115 \n",
      "Epoch : 17 Loss : 0.029 \n",
      "Epoch : 17 Loss : 0.032 \n",
      "Epoch : 17 Loss : 0.031 \n",
      "Epoch : 17 Loss : 0.031 \n",
      "Epoch : 17 Test Acc : 77.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 18 Loss : 0.006 \n",
      "Epoch : 18 Loss : 0.022 \n",
      "Epoch : 18 Loss : 0.023 \n",
      "Epoch : 18 Loss : 0.023 \n",
      "Epoch : 18 Loss : 0.027 \n",
      "Epoch : 18 Test Acc : 78.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 19 Loss : 0.090 \n",
      "Epoch : 19 Loss : 0.038 \n",
      "Epoch : 19 Loss : 0.037 \n",
      "Epoch : 19 Loss : 0.033 \n",
      "Epoch : 19 Loss : 0.034 \n",
      "Epoch : 19 Test Acc : 78.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 20 Loss : 0.009 \n",
      "Epoch : 20 Loss : 0.031 \n",
      "Epoch : 20 Loss : 0.033 \n",
      "Epoch : 20 Loss : 0.034 \n",
      "Epoch : 20 Loss : 0.033 \n",
      "Epoch : 20 Test Acc : 73.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 21 Loss : 0.019 \n",
      "Epoch : 21 Loss : 0.033 \n",
      "Epoch : 21 Loss : 0.034 \n",
      "Epoch : 21 Loss : 0.034 \n",
      "Epoch : 21 Loss : 0.033 \n",
      "Epoch : 21 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 22 Loss : 0.004 \n",
      "Epoch : 22 Loss : 0.025 \n",
      "Epoch : 22 Loss : 0.022 \n",
      "Epoch : 22 Loss : 0.021 \n",
      "Epoch : 22 Loss : 0.020 \n",
      "Epoch : 22 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 23 Loss : 0.006 \n",
      "Epoch : 23 Loss : 0.026 \n",
      "Epoch : 23 Loss : 0.027 \n",
      "Epoch : 23 Loss : 0.027 \n",
      "Epoch : 23 Loss : 0.025 \n",
      "Epoch : 23 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 24 Loss : 0.006 \n",
      "Epoch : 24 Loss : 0.010 \n",
      "Epoch : 24 Loss : 0.010 \n",
      "Epoch : 24 Loss : 0.011 \n",
      "Epoch : 24 Loss : 0.012 \n",
      "Epoch : 24 Test Acc : 76.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 25 Loss : 0.002 \n",
      "Epoch : 25 Loss : 0.015 \n",
      "Epoch : 25 Loss : 0.010 \n",
      "Epoch : 25 Loss : 0.010 \n",
      "Epoch : 25 Loss : 0.009 \n",
      "Epoch : 25 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 26 Loss : 0.002 \n",
      "Epoch : 26 Loss : 0.004 \n",
      "Epoch : 26 Loss : 0.005 \n",
      "Epoch : 26 Loss : 0.005 \n",
      "Epoch : 26 Loss : 0.005 \n",
      "Epoch : 26 Test Acc : 78.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 27 Loss : 0.002 \n",
      "Epoch : 27 Loss : 0.005 \n",
      "Epoch : 27 Loss : 0.004 \n",
      "Epoch : 27 Loss : 0.004 \n",
      "Epoch : 27 Loss : 0.004 \n",
      "Epoch : 27 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 28 Loss : 0.018 \n",
      "Epoch : 28 Loss : 0.002 \n",
      "Epoch : 28 Loss : 0.002 \n",
      "Epoch : 28 Loss : 0.002 \n",
      "Epoch : 28 Loss : 0.002 \n",
      "Epoch : 28 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 29 Loss : 0.001 \n",
      "Epoch : 29 Loss : 0.001 \n",
      "Epoch : 29 Loss : 0.001 \n",
      "Epoch : 29 Loss : 0.002 \n",
      "Epoch : 29 Loss : 0.002 \n",
      "Epoch : 29 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 30 Loss : 0.001 \n",
      "Epoch : 30 Loss : 0.001 \n",
      "Epoch : 30 Loss : 0.002 \n",
      "Epoch : 30 Loss : 0.002 \n",
      "Epoch : 30 Loss : 0.002 \n",
      "Epoch : 30 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 31 Loss : 0.001 \n",
      "Epoch : 31 Loss : 0.001 \n",
      "Epoch : 31 Loss : 0.001 \n",
      "Epoch : 31 Loss : 0.002 \n",
      "Epoch : 31 Loss : 0.002 \n",
      "Epoch : 31 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 32 Loss : 0.001 \n",
      "Epoch : 32 Loss : 0.002 \n",
      "Epoch : 32 Loss : 0.002 \n",
      "Epoch : 32 Loss : 0.002 \n",
      "Epoch : 32 Loss : 0.002 \n",
      "Epoch : 32 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 33 Loss : 0.003 \n",
      "Epoch : 33 Loss : 0.001 \n",
      "Epoch : 33 Loss : 0.001 \n",
      "Epoch : 33 Loss : 0.002 \n",
      "Epoch : 33 Loss : 0.002 \n",
      "Epoch : 33 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 34 Loss : 0.001 \n",
      "Epoch : 34 Loss : 0.001 \n",
      "Epoch : 34 Loss : 0.002 \n",
      "Epoch : 34 Loss : 0.002 \n",
      "Epoch : 34 Loss : 0.002 \n",
      "Epoch : 34 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 35 Loss : 0.000 \n",
      "Epoch : 35 Loss : 0.002 \n",
      "Epoch : 35 Loss : 0.002 \n",
      "Epoch : 35 Loss : 0.002 \n",
      "Epoch : 35 Loss : 0.002 \n",
      "Epoch : 35 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 36 Loss : 0.001 \n",
      "Epoch : 36 Loss : 0.004 \n",
      "Epoch : 36 Loss : 0.003 \n",
      "Epoch : 36 Loss : 0.002 \n",
      "Epoch : 36 Loss : 0.002 \n",
      "Epoch : 36 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 37 Loss : 0.000 \n",
      "Epoch : 37 Loss : 0.002 \n",
      "Epoch : 37 Loss : 0.001 \n",
      "Epoch : 37 Loss : 0.001 \n",
      "Epoch : 37 Loss : 0.001 \n",
      "Epoch : 37 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 38 Loss : 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 38 Loss : 0.001 \n",
      "Epoch : 38 Loss : 0.001 \n",
      "Epoch : 38 Loss : 0.001 \n",
      "Epoch : 38 Loss : 0.001 \n",
      "Epoch : 38 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 39 Loss : 0.000 \n",
      "Epoch : 39 Loss : 0.000 \n",
      "Epoch : 39 Loss : 0.001 \n",
      "Epoch : 39 Loss : 0.001 \n",
      "Epoch : 39 Loss : 0.001 \n",
      "Epoch : 39 Test Acc : 79.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 40 Loss : 0.000 \n",
      "Epoch : 40 Loss : 0.002 \n",
      "Epoch : 40 Loss : 0.002 \n",
      "Epoch : 40 Loss : 0.002 \n",
      "Epoch : 40 Loss : 0.002 \n",
      "Epoch : 40 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 41 Loss : 0.000 \n",
      "Epoch : 41 Loss : 0.000 \n",
      "Epoch : 41 Loss : 0.001 \n",
      "Epoch : 41 Loss : 0.001 \n",
      "Epoch : 41 Loss : 0.001 \n",
      "Epoch : 41 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 42 Loss : 0.000 \n",
      "Epoch : 42 Loss : 0.003 \n",
      "Epoch : 42 Loss : 0.002 \n",
      "Epoch : 42 Loss : 0.002 \n",
      "Epoch : 42 Loss : 0.002 \n",
      "Epoch : 42 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 43 Loss : 0.000 \n",
      "Epoch : 43 Loss : 0.001 \n",
      "Epoch : 43 Loss : 0.001 \n",
      "Epoch : 43 Loss : 0.001 \n",
      "Epoch : 43 Loss : 0.001 \n",
      "Epoch : 43 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 44 Loss : 0.000 \n",
      "Epoch : 44 Loss : 0.000 \n",
      "Epoch : 44 Loss : 0.002 \n",
      "Epoch : 44 Loss : 0.001 \n",
      "Epoch : 44 Loss : 0.001 \n",
      "Epoch : 44 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 45 Loss : 0.000 \n",
      "Epoch : 45 Loss : 0.000 \n",
      "Epoch : 45 Loss : 0.001 \n",
      "Epoch : 45 Loss : 0.001 \n",
      "Epoch : 45 Loss : 0.001 \n",
      "Epoch : 45 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 46 Loss : 0.000 \n",
      "Epoch : 46 Loss : 0.000 \n",
      "Epoch : 46 Loss : 0.001 \n",
      "Epoch : 46 Loss : 0.001 \n",
      "Epoch : 46 Loss : 0.001 \n",
      "Epoch : 46 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 47 Loss : 0.001 \n",
      "Epoch : 47 Loss : 0.000 \n",
      "Epoch : 47 Loss : 0.001 \n",
      "Epoch : 47 Loss : 0.001 \n",
      "Epoch : 47 Loss : 0.001 \n",
      "Epoch : 47 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 48 Loss : 0.000 \n",
      "Epoch : 48 Loss : 0.001 \n",
      "Epoch : 48 Loss : 0.001 \n",
      "Epoch : 48 Loss : 0.001 \n",
      "Epoch : 48 Loss : 0.001 \n",
      "Epoch : 48 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 49 Loss : 0.001 \n",
      "Epoch : 49 Loss : 0.000 \n",
      "Epoch : 49 Loss : 0.001 \n",
      "Epoch : 49 Loss : 0.001 \n",
      "Epoch : 49 Loss : 0.001 \n",
      "Epoch : 49 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "acc = []\n",
    "epoches= 50\n",
    "for epoch in range(epoches):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\\\n",
    "y_pred, y_test = trainer.predict()\n",
    "class_names = ['Cat', 'Dog']\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "        outputs = clf(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        accuracy = 100. * (correct/total)\n",
    "        acc.append(accuracy)\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print('--------------------------------------------------------------')\n",
    "    clf.train()\n",
    "    \n",
    "    c += 1\n",
    "     \n",
    "    if (c%5 == 0)  and (acc[epoch] <= min(acc[epoch-4:epoch-1])):\n",
    "        learning_rate *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[]]\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    if cuda_available:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    outputs = clf(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    results = np.append(results, predicted.cpu().numpy())\n",
    "\n",
    "results = np.int8(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'id': range(1, len(results)+1),\n",
    "                    'label': results})\n",
    "df['label'].replace([0,1], ['Cat','Dog'], inplace=True)\n",
    "df[df.columns].to_csv('submisstion.csv',index=False)\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer1():\n",
    "    for epoch in range(epoches):\n",
    "        losses = []\n",
    "        # Train\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            if cuda_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "\n",
    "            if batch_idx%50==0:\n",
    "                print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "            if cuda_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "        print('--------------------------------------------------------------')\n",
    "        model.train()\n",
    "    print('Done...')\n",
    "\n",
    "trainer1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
