{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "# import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchvision.datasets.folder.ImageFolder object at 0x7f0809188828>\n",
      "<torchvision.datasets.folder.ImageFolder object at 0x7f0809188a58>\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(\n",
    "                    root='./data/trainset/',\n",
    "                    transform=transforms\n",
    "                    )\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "                    root= './data/test/', \n",
    "                    transform=transforms)\n",
    "\n",
    "dataset_ratio = np.array([95, 5])/100\n",
    "\n",
    "sizes = [int(x*len(data)) for x in dataset_ratio]\n",
    "sizes[0] += len(data) - sum(sizes)\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=data, lengths=sizes)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=False\n",
    "                    )\n",
    "print(data)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "lr0 = 0.002\n",
    "optim = 'adam'\n",
    "num_epochs = 10\n",
    "store_every = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a residual convolution block to be used in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1, activation = nn.ReLU):\n",
    "        super(ResidualConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu1 = nn.ReLU(in_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu2 = nn.ReLU(in_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "#             self.projected_conv = self.conv1x1(in_channels, out_channels)\n",
    "            self.project_linear = nn.Linear(in_channels, out_channels)\n",
    "    def forward(x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.in_channels == self.out_channels:\n",
    "            out += identity\n",
    "        else:\n",
    "            out += self.project_linear(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "    def conv1x1(in_channels, out_channels, stride=1):\n",
    "        \"\"\"1x1 convolution\"\"\"\n",
    "        print()\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            ResidualConv(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            ResidualConv(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            ResidualConv(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(64, 2)\n",
    "        \n",
    "        def forward(x):\n",
    "            return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanilaCNN(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(VanilaCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 6\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanilaCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU()\n",
      "    (17): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 64, 64]             448\n",
      "              ReLU-2           [-1, 16, 64, 64]               0\n",
      "         MaxPool2d-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]           4,640\n",
      "              ReLU-5           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-6           [-1, 32, 16, 16]               0\n",
      "            Conv2d-7           [-1, 64, 16, 16]          18,496\n",
      "              ReLU-8           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-9             [-1, 64, 8, 8]               0\n",
      "           Conv2d-10            [-1, 128, 8, 8]          73,856\n",
      "             ReLU-11            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-12            [-1, 128, 4, 4]               0\n",
      "           Conv2d-13            [-1, 128, 4, 4]         147,584\n",
      "             ReLU-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "           Conv2d-16            [-1, 256, 2, 2]         295,168\n",
      "             ReLU-17            [-1, 256, 2, 2]               0\n",
      "        MaxPool2d-18            [-1, 256, 1, 1]               0\n",
      "           Linear-19                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 540,706\n",
      "Trainable params: 540,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.16\n",
      "Params size (MB): 2.06\n",
      "Estimated Total Size (MB): 4.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
