{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "                    root='./data/trainset/',\n",
    "                    transform=transforms\n",
    "                    )\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "                    root= './data/test/', \n",
    "                    transform=transforms)\n",
    "\n",
    "train_set_ratio = 0.8\n",
    "size = [int(len(train_data)*train_set_ratio), len(train_data) - int(len(train_data)*train_set_ratio)]\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=train_data, lengths=size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=False\n",
    "                    )\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 6\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "if cuda_available:\n",
    "    clf = clf.cuda()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 0.005 \n",
      "Epoch : 0 Loss : 0.019 \n",
      "Epoch : 0 Loss : 0.018 \n",
      "Epoch : 0 Loss : 0.019 \n",
      "Epoch : 0 Loss : 0.022 \n",
      "Epoch : 0 Test Acc : 82.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 0.002 \n",
      "Epoch : 1 Loss : 0.010 \n",
      "Epoch : 1 Loss : 0.011 \n",
      "Epoch : 1 Loss : 0.010 \n",
      "Epoch : 1 Loss : 0.011 \n",
      "Epoch : 1 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Loss : 0.002 \n",
      "Epoch : 2 Loss : 0.007 \n",
      "Epoch : 2 Loss : 0.009 \n",
      "Epoch : 2 Loss : 0.010 \n",
      "Epoch : 2 Loss : 0.012 \n",
      "Epoch : 2 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Loss : 0.002 \n",
      "Epoch : 3 Loss : 0.017 \n",
      "Epoch : 3 Loss : 0.015 \n",
      "Epoch : 3 Loss : 0.015 \n",
      "Epoch : 3 Loss : 0.014 \n",
      "Epoch : 3 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Loss : 0.001 \n",
      "Epoch : 4 Loss : 0.009 \n",
      "Epoch : 4 Loss : 0.008 \n",
      "Epoch : 4 Loss : 0.009 \n",
      "Epoch : 4 Loss : 0.012 \n",
      "Epoch : 4 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Loss : 0.046 \n",
      "Epoch : 5 Loss : 0.015 \n",
      "Epoch : 5 Loss : 0.012 \n",
      "Epoch : 5 Loss : 0.010 \n",
      "Epoch : 5 Loss : 0.011 \n",
      "Epoch : 5 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Loss : 0.112 \n",
      "Epoch : 6 Loss : 0.019 \n",
      "Epoch : 6 Loss : 0.014 \n",
      "Epoch : 6 Loss : 0.014 \n",
      "Epoch : 6 Loss : 0.014 \n",
      "Epoch : 6 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Loss : 0.001 \n",
      "Epoch : 7 Loss : 0.017 \n",
      "Epoch : 7 Loss : 0.026 \n",
      "Epoch : 7 Loss : 0.025 \n",
      "Epoch : 7 Loss : 0.021 \n",
      "Epoch : 7 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Loss : 0.001 \n",
      "Epoch : 8 Loss : 0.011 \n",
      "Epoch : 8 Loss : 0.020 \n",
      "Epoch : 8 Loss : 0.019 \n",
      "Epoch : 8 Loss : 0.018 \n",
      "Epoch : 8 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 9 Loss : 0.008 \n",
      "Epoch : 9 Loss : 0.022 \n",
      "Epoch : 9 Loss : 0.016 \n",
      "Epoch : 9 Loss : 0.015 \n",
      "Epoch : 9 Loss : 0.016 \n",
      "Epoch : 9 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 10 Loss : 0.007 \n",
      "Epoch : 10 Loss : 0.013 \n",
      "Epoch : 10 Loss : 0.016 \n",
      "Epoch : 10 Loss : 0.017 \n",
      "Epoch : 10 Loss : 0.016 \n",
      "Epoch : 10 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 11 Loss : 0.031 \n",
      "Epoch : 11 Loss : 0.011 \n",
      "Epoch : 11 Loss : 0.023 \n",
      "Epoch : 11 Loss : 0.022 \n",
      "Epoch : 11 Loss : 0.020 \n",
      "Epoch : 11 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 12 Loss : 0.002 \n",
      "Epoch : 12 Loss : 0.007 \n",
      "Epoch : 12 Loss : 0.007 \n",
      "Epoch : 12 Loss : 0.006 \n",
      "Epoch : 12 Loss : 0.009 \n",
      "Epoch : 12 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 13 Loss : 0.005 \n",
      "Epoch : 13 Loss : 0.013 \n",
      "Epoch : 13 Loss : 0.009 \n",
      "Epoch : 13 Loss : 0.007 \n",
      "Epoch : 13 Loss : 0.007 \n",
      "Epoch : 13 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 14 Loss : 0.070 \n",
      "Epoch : 14 Loss : 0.012 \n",
      "Epoch : 14 Loss : 0.016 \n",
      "Epoch : 14 Loss : 0.018 \n",
      "Epoch : 14 Loss : 0.018 \n",
      "Epoch : 14 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 15 Loss : 0.005 \n",
      "Epoch : 15 Loss : 0.027 \n",
      "Epoch : 15 Loss : 0.031 \n",
      "Epoch : 15 Loss : 0.023 \n",
      "Epoch : 15 Loss : 0.021 \n",
      "Epoch : 15 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 16 Loss : 0.001 \n",
      "Epoch : 16 Loss : 0.003 \n",
      "Epoch : 16 Loss : 0.004 \n",
      "Epoch : 16 Loss : 0.004 \n",
      "Epoch : 16 Loss : 0.005 \n",
      "Epoch : 16 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 17 Loss : 0.033 \n",
      "Epoch : 17 Loss : 0.017 \n",
      "Epoch : 17 Loss : 0.014 \n",
      "Epoch : 17 Loss : 0.015 \n",
      "Epoch : 17 Loss : 0.014 \n",
      "Epoch : 17 Test Acc : 82.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 18 Loss : 0.001 \n",
      "Epoch : 18 Loss : 0.008 \n",
      "Epoch : 18 Loss : 0.011 \n",
      "Epoch : 18 Loss : 0.013 \n",
      "Epoch : 18 Loss : 0.016 \n",
      "Epoch : 18 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 19 Loss : 0.001 \n",
      "Epoch : 19 Loss : 0.015 \n",
      "Epoch : 19 Loss : 0.014 \n",
      "Epoch : 19 Loss : 0.016 \n",
      "Epoch : 19 Loss : 0.015 \n",
      "Epoch : 19 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 20 Loss : 0.006 \n",
      "Epoch : 20 Loss : 0.016 \n",
      "Epoch : 20 Loss : 0.013 \n",
      "Epoch : 20 Loss : 0.012 \n",
      "Epoch : 20 Loss : 0.014 \n",
      "Epoch : 20 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 21 Loss : 0.017 \n",
      "Epoch : 21 Loss : 0.019 \n",
      "Epoch : 21 Loss : 0.014 \n",
      "Epoch : 21 Loss : 0.013 \n",
      "Epoch : 21 Loss : 0.011 \n",
      "Epoch : 21 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 22 Loss : 0.005 \n",
      "Epoch : 22 Loss : 0.016 \n",
      "Epoch : 22 Loss : 0.012 \n",
      "Epoch : 22 Loss : 0.012 \n",
      "Epoch : 22 Loss : 0.015 \n",
      "Epoch : 22 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 23 Loss : 0.028 \n",
      "Epoch : 23 Loss : 0.015 \n",
      "Epoch : 23 Loss : 0.012 \n",
      "Epoch : 23 Loss : 0.010 \n",
      "Epoch : 23 Loss : 0.009 \n",
      "Epoch : 23 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 24 Loss : 0.004 \n",
      "Epoch : 24 Loss : 0.024 \n",
      "Epoch : 24 Loss : 0.019 \n",
      "Epoch : 24 Loss : 0.016 \n",
      "Epoch : 24 Loss : 0.015 \n",
      "Epoch : 24 Test Acc : 82.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 25 Loss : 0.000 \n",
      "Epoch : 25 Loss : 0.007 \n",
      "Epoch : 25 Loss : 0.005 \n",
      "Epoch : 25 Loss : 0.003 \n",
      "Epoch : 25 Loss : 0.003 \n",
      "Epoch : 25 Test Acc : 82.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 26 Loss : 0.000 \n",
      "Epoch : 26 Loss : 0.001 \n",
      "Epoch : 26 Loss : 0.001 \n",
      "Epoch : 26 Loss : 0.001 \n",
      "Epoch : 26 Loss : 0.004 \n",
      "Epoch : 26 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 27 Loss : 0.010 \n",
      "Epoch : 27 Loss : 0.031 \n",
      "Epoch : 27 Loss : 0.030 \n",
      "Epoch : 27 Loss : 0.023 \n",
      "Epoch : 27 Loss : 0.019 \n",
      "Epoch : 27 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 28 Loss : 0.016 \n",
      "Epoch : 28 Loss : 0.034 \n",
      "Epoch : 28 Loss : 0.021 \n",
      "Epoch : 28 Loss : 0.023 \n",
      "Epoch : 28 Loss : 0.027 \n",
      "Epoch : 28 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 29 Loss : 0.001 \n",
      "Epoch : 29 Loss : 0.007 \n",
      "Epoch : 29 Loss : 0.012 \n",
      "Epoch : 29 Loss : 0.011 \n",
      "Epoch : 29 Loss : 0.012 \n",
      "Epoch : 29 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 30 Loss : 0.001 \n",
      "Epoch : 30 Loss : 0.006 \n",
      "Epoch : 30 Loss : 0.010 \n",
      "Epoch : 30 Loss : 0.013 \n",
      "Epoch : 30 Loss : 0.016 \n",
      "Epoch : 30 Test Acc : 80.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 31 Loss : 0.016 \n",
      "Epoch : 31 Loss : 0.007 \n",
      "Epoch : 31 Loss : 0.006 \n",
      "Epoch : 31 Loss : 0.006 \n",
      "Epoch : 31 Loss : 0.006 \n",
      "Epoch : 31 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 32 Loss : 0.000 \n",
      "Epoch : 32 Loss : 0.010 \n",
      "Epoch : 32 Loss : 0.014 \n",
      "Epoch : 32 Loss : 0.014 \n",
      "Epoch : 32 Loss : 0.014 \n",
      "Epoch : 32 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 33 Loss : 0.004 \n",
      "Epoch : 33 Loss : 0.006 \n",
      "Epoch : 33 Loss : 0.006 \n",
      "Epoch : 33 Loss : 0.006 \n",
      "Epoch : 33 Loss : 0.011 \n",
      "Epoch : 33 Test Acc : 81.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 34 Loss : 0.002 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-3576cc1563ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoches= 50\n",
    "for epoch in range(epoches):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = clf(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        if batch_idx%50==0:\n",
    "            print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    clf.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = clf(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print('--------------------------------------------------------------')\n",
    "    clf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating of testset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[]]\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    if cuda_available:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    outputs = clf(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    results = np.append(results, predicted.cpu().numpy())\n",
    "\n",
    "results = np.int8(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'id': range(1, len(results)+1),\n",
    "                    'label': results})\n",
    "df['label'].replace([0,1], ['Cat','Dog'], inplace=True)\n",
    "df[df.columns].to_csv('submisstion.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
