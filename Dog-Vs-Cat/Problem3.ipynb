{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring sacred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 19998\n",
      "    Root Location: ./data/trainset/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "<torch.utils.data.dataset.Subset object at 0x7ffb29fb5a58>\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(\n",
    "                    root='./data/trainset/',\n",
    "                    transform=transforms\n",
    "                    )\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "                    root= './data/test/', \n",
    "                    transform=transforms)\n",
    "\n",
    "dataset_ratio = np.array([95, 5])/100\n",
    "\n",
    "sizes = [int(x*len(data)) for x in dataset_ratio]\n",
    "sizes[0] += len(data) - sum(sizes)\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=data, lengths=sizes)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=False\n",
    "                    )\n",
    "print(data)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "lr0 = 0.02\n",
    "optim = 'sgd'\n",
    "num_epochs = 10\n",
    "store_every = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a residual convolution block to be used in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1, activation = nn.ReLU):\n",
    "        super(ResidualConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu1 = nn.ReLU(in_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.relu2 = nn.ReLU(in_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "#             self.projected_conv = self.conv1x1(in_channels, out_channels)\n",
    "            self.project_linear = nn.Linear(in_channels, out_channels)\n",
    "    def forward(x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.in_channels == self.out_channels:\n",
    "            out += identity\n",
    "        else:\n",
    "            out += self.project_linear(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "    def conv1x1(in_channels, out_channels, stride=1):\n",
    "        \"\"\"1x1 convolution\"\"\"\n",
    "        print()\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            ResidualConv(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            ResidualConv(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            ResidualConv(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(64, 2)\n",
    "        \n",
    "        def forward(x):\n",
    "            return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanilaCNN(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(VanilaCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 6\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['ResidualClassifier', \"VanilaCNN\", \"VanilaCNN2\"]\n",
    "my_classifier = 'ResidualClassifier'\n",
    "\n",
    "if my_classifier=='ResidualClassifier':\n",
    "    model = ResidualClassifier()\n",
    "elif my_classifier=='VanilaCNN':\n",
    "    model = VanilaCNN() \n",
    "elif my_classifier=='VanilaCNN2':\n",
    "    model = VanilaCNN2()\n",
    "    \n",
    "if cuda_available:\n",
    "    model = model.cuda()\n",
    "if optim == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "elif optim == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualClassifier(\n",
      "  (conv): Sequential(\n",
      "    (0): ResidualConv(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=3, out_features=16, bias=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ResidualConv(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=16, out_features=32, bias=True)\n",
      "    )\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ResidualConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=32, out_features=64, bias=True)\n",
      "    )\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualClassifier(\n",
      "  (conv): Sequential(\n",
      "    (0): ResidualConv(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=3, out_features=16, bias=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ResidualConv(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=16, out_features=32, bias=True)\n",
      "    )\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ResidualConv(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu2): ReLU(inplace)\n",
      "      (project_linear): Linear(in_features=32, out_features=64, bias=True)\n",
      "    )\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7ffb2a8bdf98>\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c20c0508da76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mnll_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c20c0508da76>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Trainer2():\n",
    "    def evaluate(dataset_loader, criterion):\n",
    "        LOSSES = 0\n",
    "        COUNTER = 0\n",
    "        for batch in dataset_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = batch\n",
    "    #             x = x.view(-1,1,28,28)\n",
    "            y = y.view(-1)\n",
    "            if cuda_available:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            loss = criterion(model(x), y)\n",
    "            n = y.size(0)\n",
    "            LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "            COUNTER += n\n",
    "\n",
    "        return LOSSES / float(COUNTER)\n",
    "    \n",
    "    def accuracy(proba, y):\n",
    "        correct = torch.eq(proba.max(1)[1], y).sum().type(torch.FloatTensor)\n",
    "        return correct / y.size(0)\n",
    "    \n",
    "    def adjust_lr(optimizer, epoch, total_epochs):\n",
    "        lr = lr0 * (0.1 ** (epoch / float(total_epochs)))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def train_model(self, model, optimizer, criterion):\n",
    "        LOSSES = 0\n",
    "        COUNTER = 0\n",
    "        ITERATIONS = 0\n",
    "        learning_curve_nll_train = list()\n",
    "        learning_curve_nll_test = list()\n",
    "        learning_curve_acc_train = list()\n",
    "        learning_curve_acc_test = list()\n",
    "        for e in range(num_epochs):\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                print(train_loader)\n",
    "                x, y = batch\n",
    "    #             x = x.view(-1,1,28,28)\n",
    "                y = y.view(-1)\n",
    "                if cuda_available:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                \n",
    "                loss = criterion(model(x), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                n = y.size(0)\n",
    "                LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "                COUNTER += n\n",
    "                ITERATIONS += 1\n",
    "                if ITERATIONS%(store_every/5) == 0:\n",
    "                    avg_loss = LOSSES / float(COUNTER)\n",
    "                    LOSSES = 0\n",
    "                    COUNTER = 0\n",
    "                    print(\" Iteration {}: TRAIN {}\".format(\n",
    "                        ITERATIONS, avg_loss))\n",
    "\n",
    "                if ITERATIONS%(store_every) == 0:     \n",
    "\n",
    "                    train_loss = evaluate(train_loader, criterion)\n",
    "                    learning_curve_nll_train.append(train_loss)\n",
    "                    test_loss = evaluate(test_loader, criterion)\n",
    "                    learning_curve_nll_test.append(test_loss)\n",
    "\n",
    "                    train_acc = evaluate(train_loader, accuracy)\n",
    "                    learning_curve_acc_train.append(train_acc)\n",
    "                    test_acc = evaluate(valid_loader, accuracy)\n",
    "                    learning_curve_acc_test.append(test_acc)\n",
    "\n",
    "                    print(\" [NLL] TRAIN {} / TEST {}\".format(\n",
    "                        train_loss, test_loss))\n",
    "                    print(\" [ACC] TRAIN {} / TEST {}\".format(\n",
    "                        train_acc, test_acc))\n",
    "\n",
    "            adjust_lr(optimizer, e+1, num_epochs)\n",
    "\n",
    "        return learning_curve_nll_train, \\\n",
    "               learning_curve_nll_test, \\\n",
    "               learning_curve_acc_train, \\\n",
    "               learning_curve_acc_test, \n",
    "    \n",
    "trainer = Trainer2();\n",
    "nll_train, nll_test, acc_train, acc_test =  trainer.train_model(model, optimizer, criterion)\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(acc_train))\n",
    "plt.figure(1)\n",
    "plt.plot(range(len(nll_train)), nll_train, label=\"NLL train\" )\n",
    "plt.plot(range(len(nll_test)), nll_test,   label=\"NLL test\" )\n",
    "plt.figure(2)\n",
    "plt.plot(range(len(acc_train)), acc_train, label=\"Accuracy train\" )\n",
    "plt.plot(range(len(acc_test)), acc_test,   label=\"Accuracy test\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating of testset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[]]\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    if cuda_available:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    outputs = clf(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    results = np.append(results, predicted.cpu().numpy())\n",
    "\n",
    "results = np.int8(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'id': range(1, len(results)+1),\n",
    "                    'label': results})\n",
    "df['label'].replace([0,1], ['Cat','Dog'], inplace=True)\n",
    "df[df.columns].to_csv('submisstion.csv',index=False)\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer1():\n",
    "    for epoch in range(epoches):\n",
    "        losses = []\n",
    "        # Train\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            if cuda_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "\n",
    "            if batch_idx%50==0:\n",
    "                print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "            if cuda_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "        print('--------------------------------------------------------------')\n",
    "        model.train()\n",
    "    print('Done...')\n",
    "\n",
    "trainer1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
