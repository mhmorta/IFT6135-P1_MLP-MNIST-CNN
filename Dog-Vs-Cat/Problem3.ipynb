{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Xtraining shape:', (19998, 64, 64, 3))\n",
      "('Ytraining shape:', (19998, 1))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Required argument 'mat' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7c458d9a764f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ytraining shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'mat' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "training_list = glob.glob('./data/trainset/*')\n",
    "test_list = glob.glob('./data/testset/')\n",
    "\n",
    "Xtraining = []\n",
    "Ytraining = []\n",
    "for folder in training_list:\n",
    "    img_list = (glob.glob(folder+'/*'))\n",
    "    category = img_list[0].split('/')[-1].split('.')[1]\n",
    "    for img in img_list:\n",
    "        image = cv2.imread(img)\n",
    "        Xtraining.append(image)\n",
    "    if category == 'Dog':\n",
    "        Ytraining.append(np.ones([len(img_list),1]))\n",
    "    else:\n",
    "        Ytraining.append(np.zeros([len(img_list),1]))\n",
    "\n",
    "Xtraining = np.array(Xtraining)\n",
    "Ytraining = np.array(Ytraining, dtype=int).reshape([-1,1])\n",
    "print('Xtraining shape:', Xtraining.shape)    \n",
    "print('Ytraining shape:', Ytraining.shape)\n",
    "\n",
    "cv2.imshow(Xtraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\".data\"):\n",
    "    for filename in [f for f in filenames if f.endswith(\".Cat.jpg\")]:\n",
    "        print (os.path.join(dirpath, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
